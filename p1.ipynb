{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")  # 导入评估指标\n",
    "from scipy.stats import randint, uniform  # 用于定义随机搜索的参数分布\n",
    "import warnings\n",
    "import os  # 引入os模块检查文件是否存在\n",
    "\n",
    "# 忽略可能的警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 配置 ---\n",
    "file_path = \"/Users/pp/projects/51MCM2025/program/a1.csv\"  # 确保文件路径正确\n",
    "prediction_date = datetime(2024, 7, 21)\n",
    "historical_start_date = datetime(2024, 7, 11)\n",
    "historical_end_date = datetime(2024, 7, 20)\n",
    "lookback_days = 3  # 使用前 k 天的数据作为特征，这里 k=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据: /Users/pp/projects/51MCM2025/program/a1.csv...\n",
      "数据加载完成.\n",
      "正在转换时间格式...\n",
      "时间格式转换完成.\n",
      "正在过滤数据范围至 2024-07-11 - 2024-07-20...\n",
      "过滤完成，剩余 2210440 条数据.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 检查文件是否存在 ---\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"错误：文件未找到 - {file_path}\")\n",
    "    print(\"请确保 '附件1.csv' 文件与脚本在同一目录下。\")\n",
    "    exit()\n",
    "\n",
    "# --- 1. 数据加载与预处理 ---\n",
    "print(f\"正在加载数据: {file_path}...\")\n",
    "try:\n",
    "    # 尝试更高效的读取方式，指定dtype\n",
    "    dtype_spec = {\n",
    "        \"UserID\": \"category\",\n",
    "        \"UserBehaviour\": \"int8\",\n",
    "        \"BloggerID\": \"category\",\n",
    "        \"Time\": \"object\",  # 先读object，再转datetime\n",
    "    }\n",
    "    df = pd.read_csv(file_path, dtype=dtype_spec, low_memory=False)\n",
    "    print(\"数据加载完成.\")\n",
    "\n",
    "    # 转换时间列\n",
    "    print(\"正在转换时间格式...\")\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "    df[\"Date\"] = df[\"Time\"].dt.date\n",
    "    print(\"时间格式转换完成.\")\n",
    "\n",
    "    # 过滤历史数据范围\n",
    "    print(\n",
    "        f\"正在过滤数据范围至 {historical_start_date.date()} - {historical_end_date.date()}...\"\n",
    "    )\n",
    "    df_history = df[\n",
    "        (df[\"Date\"] >= historical_start_date.date())\n",
    "        & (df[\"Date\"] <= historical_end_date.date())\n",
    "    ].copy()\n",
    "    print(f\"过滤完成，剩余 {len(df_history)} 条数据.\")\n",
    "\n",
    "    # 释放原始大DataFrame内存\n",
    "    del df\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"数据加载或初步处理失败: {e}\")\n",
    "    exit()  # 如果数据加载失败，直接退出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 42 位博主在历史数据中出现.\n",
      "正在计算每日博主互动计数...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 获取所有独特的博主ID，后续预测需要为所有这些博主进行\n",
    "all_blogger_ids = df_history[\"BloggerID\"].unique()\n",
    "print(f\"共有 {len(all_blogger_ids)} 位博主在历史数据中出现.\")\n",
    "\n",
    "# --- 2. 计算每日互动计数 ---\n",
    "print(\"正在计算每日博主互动计数...\")\n",
    "# 使用pivot_table更方便地获取各种行为的每日计数\n",
    "daily_interactions = (\n",
    "    pd.pivot_table(\n",
    "        df_history,\n",
    "        values=\"UserID\",  # 任意一个值列即可，我们只关心计数\n",
    "        index=[\"BloggerID\", \"Date\"],\n",
    "        columns=\"UserBehaviour\",\n",
    "        aggfunc=\"count\",\n",
    "        fill_value=0,  # 关键：用0填充没有发生某种行为的日期/博主组合\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            1: \"watch_count\",\n",
    "            2: \"like_count\",\n",
    "            3: \"comment_count\",\n",
    "            4: \"follow_count\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每日互动计数计算完成.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 确保所有博主在所有历史日期都有记录，即使计数为0\n",
    "# 创建所有博主和历史日期的组合\n",
    "all_dates_in_history = pd.date_range(\n",
    "    start=historical_start_date.date(), end=historical_end_date.date(), freq=\"D\"\n",
    ").date\n",
    "all_blogger_date_combinations = pd.MultiIndex.from_product(\n",
    "    [all_blogger_ids, all_dates_in_history], names=[\"BloggerID\", \"Date\"]\n",
    ")\n",
    "daily_interactions = (\n",
    "    daily_interactions.set_index([\"BloggerID\", \"Date\"])\n",
    "    .reindex(all_blogger_date_combinations, fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"每日互动计数计算完成.\")\n",
    "# print(daily_interactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在构建训练数据集 (使用前 3 天数据预测当天)...\n",
      "训练数据集构建完成，共 294 个样本.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. 构建训练数据集 ---\n",
    "print(f\"正在构建训练数据集 (使用前 {lookback_days} 天数据预测当天)...\")\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "train_samples_meta = []  # 存储样本对应的博主和日期\n",
    "\n",
    "# 训练的目标日期范围：从 historical_start_date + lookback_days 到 historical_end_date\n",
    "train_start_date = historical_start_date + timedelta(days=lookback_days)\n",
    "train_end_date = historical_end_date\n",
    "\n",
    "# 确保训练数据日期范围有效\n",
    "if train_start_date > historical_end_date:\n",
    "    print(\n",
    "        f\"错误：历史数据范围 ({historical_start_date.date()} - {historical_end_date.date()}) 太短，无法构建训练集 (需要至少 {lookback_days + 1} 天).\"\n",
    "    )\n",
    "    exit()\n",
    "\n",
    "current_train_date = train_start_date\n",
    "while current_train_date <= train_end_date:\n",
    "    lookback_end = current_train_date - timedelta(days=1)\n",
    "    lookback_start = current_train_date - timedelta(days=lookback_days)\n",
    "\n",
    "    # 提取当前训练日期的目标数据\n",
    "    target_day_data = daily_interactions[\n",
    "        daily_interactions[\"Date\"] == current_train_date.date()\n",
    "    ]\n",
    "\n",
    "    # 提取当前训练日期的特征数据（前 lookback_days 的汇总）\n",
    "    feature_window_data = daily_interactions[\n",
    "        (daily_interactions[\"Date\"] >= lookback_start.date())\n",
    "        & (daily_interactions[\"Date\"] <= lookback_end.date())\n",
    "    ]\n",
    "\n",
    "    # 按博主ID汇总特征窗口内的数据\n",
    "    features_aggregated = (\n",
    "        feature_window_data.groupby(\"BloggerID\")[\n",
    "            [\"watch_count\", \"like_count\", \"comment_count\", \"follow_count\"]\n",
    "        ]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    features_aggregated.rename(\n",
    "        columns={\n",
    "            \"watch_count\": \"sum_watch_prev\",\n",
    "            \"like_count\": \"sum_like_prev\",\n",
    "            \"comment_count\": \"sum_comment_prev\",\n",
    "            \"follow_count\": \"sum_follow_prev\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # 迭代所有博主，为每个博主在当前训练日期构建样本\n",
    "    for blogger_id in all_blogger_ids:\n",
    "        # 获取特征 (处理可能没有数据的博主)\n",
    "        blogger_features = features_aggregated[\n",
    "            features_aggregated[\"BloggerID\"] == blogger_id\n",
    "        ]\n",
    "        if blogger_features.empty:\n",
    "            features_row = [0, 0, 0, 0]  # 如果前lookback_days没有数据，特征为0\n",
    "        else:\n",
    "            features_row = (\n",
    "                blogger_features[\n",
    "                    [\n",
    "                        \"sum_watch_prev\",\n",
    "                        \"sum_like_prev\",\n",
    "                        \"sum_comment_prev\",\n",
    "                        \"sum_follow_prev\",\n",
    "                    ]\n",
    "                ]\n",
    "                .iloc[0]\n",
    "                .tolist()\n",
    "            )\n",
    "\n",
    "        # 获取目标 (处理当天没有关注的博主)\n",
    "        blogger_target = target_day_data[target_day_data[\"BloggerID\"] == blogger_id]\n",
    "        target_value = (\n",
    "            blogger_target[\"follow_count\"].iloc[0] if not blogger_target.empty else 0\n",
    "        )  # 如果当天没数据，目标为0\n",
    "\n",
    "        X_train.append(features_row)\n",
    "        y_train.append(target_value)\n",
    "        train_samples_meta.append(\n",
    "            (blogger_id, current_train_date.date())\n",
    "        )  # 记录样本元数据\n",
    "\n",
    "    current_train_date += timedelta(days=1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"训练数据集构建完成，共 {len(X_train)} 个样本.\")\n",
    "# print(\"X_train sample:\", X_train[:5])\n",
    "# print(\"y_train sample:\", y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在进行参数调优 (RandomizedSearchCV)...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "参数调优完成.\n",
      "最佳参数组合: {'max_depth': np.int64(37), 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 137}\n",
      "最佳交叉验证得分 (负MAE): -24.703995334342853\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. 参数调优 ---\n",
    "print(\"\\n正在进行参数调优 (RandomizedSearchCV)...\")\n",
    "\n",
    "# 定义参数搜索空间\n",
    "param_distributions = {\n",
    "    \"n_estimators\": randint(50, 301),  # 树的数量在 50 到 300 之间随机整数\n",
    "    \"max_depth\": [None]\n",
    "    + list(\n",
    "        randint(10, 51).rvs(size=20)\n",
    "    ),  # 最大深度可以是 None，或者 10 到 50 之间的一些随机整数 (减少样本数量)\n",
    "    \"min_samples_split\": randint(2, 21),  # 分裂所需的最小样本数在 2 到 20 之间随机整数\n",
    "    \"min_samples_leaf\": randint(1, 11),  # 叶节点所需的最小样本数在 1 到 10 之间随机整数\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 1.0],  # 寻找最佳分裂时考虑的特征数量\n",
    "}\n",
    "\n",
    "# 交叉验证策略\n",
    "# 使用 KFold with shuffle。cv=5 表示 5折交叉验证。\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化 RandomizedSearchCV\n",
    "# n_iter: 随机采样的参数组合数量。这里设置为 50 次尝试，可以根据计算资源调整。\n",
    "# scoring: 使用负平均绝对误差作为评估指标，越高越好 (因为是负的误差)。\n",
    "# random_state: 保证结果可复现。\n",
    "# n_jobs=-1: 利用所有核心进行并行计算。\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),  # 传入一个基础模型实例\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # 尝试 50 个不同的参数组合，这个值可以根据计算资源调整\n",
    "    cv=cv_strategy,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    verbose=1,  # 打印进度信息\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 在训练数据上运行随机搜索\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n参数调优完成.\")\n",
    "print(\"最佳参数组合:\", random_search.best_params_)\n",
    "print(\"最佳交叉验证得分 (负MAE):\", random_search.best_score_)  # 这是负MAE，值越大越好\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在使用最优参数训练最终模型...\n",
      "最终模型训练完成 (使用最佳参数).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. 使用最优参数训练最终模型 ---\n",
    "print(\"\\n正在使用最优参数训练最终模型...\")\n",
    "final_model = random_search.best_estimator_  # 获取带有最佳参数的训练好的模型实例\n",
    "# 注意：best_estimator_ 已经在训练数据上拟合过了，可以直接用于预测\n",
    "\n",
    "print(\"最终模型训练完成 (使用最佳参数).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在评价最终模型在训练集上的性能...\n",
      "训练集评估结果:\n",
      "  平均绝对误差 (MAE): 18.2211\n",
      "  均方误差 (MSE): 712.2619\n",
      "  均方根误差 (RMSE): 26.6882\n",
      "  决定系数 (R²): 0.9491\n",
      "模型评价完成.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 6. 模型在训练集上的评价 ---\n",
    "print(\"\\n正在评价最终模型在训练集上的性能...\")\n",
    "\n",
    "# 使用训练好的模型对训练集进行预测\n",
    "y_train_pred = final_model.predict(X_train)\n",
    "\n",
    "# 确保预测结果非负并四舍五入取整，以便与真实值对比\n",
    "y_train_pred_rounded = np.round(y_train_pred).astype(int)\n",
    "y_train_pred_rounded[y_train_pred_rounded < 0] = 0\n",
    "\n",
    "# 计算评估指标\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred_rounded)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred_rounded)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "r2_train = r2_score(y_train, y_train_pred_rounded)\n",
    "\n",
    "print(f\"训练集评估结果:\")\n",
    "print(f\"  平均绝对误差 (MAE): {mae_train:.4f}\")\n",
    "print(f\"  均方误差 (MSE): {mse_train:.4f}\")\n",
    "print(f\"  均方根误差 (RMSE): {rmse_train:.4f}\")\n",
    "print(f\"  决定系数 (R²): {r2_train:.4f}\")\n",
    "\n",
    "print(\"模型评价完成.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在构建预测数据集 (使用 2024-07-18 - 2024-07-20 数据预测 2024-07-21)...\n",
      "预测数据集构建完成，共 42 个样本.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 7. 构建预测数据集 ---\n",
    "print(\n",
    "    f\"\\n正在构建预测数据集 (使用 {prediction_date.date()-timedelta(days=lookback_days)} - {prediction_date.date()-timedelta(days=1)} 数据预测 {prediction_date.date()})...\"\n",
    ")\n",
    "\n",
    "# 预测窗口： 7.18 到 7.20 (如果 lookback_days=3)\n",
    "prediction_feature_start_date = prediction_date - timedelta(days=lookback_days)\n",
    "prediction_feature_end_date = prediction_date - timedelta(days=1)\n",
    "\n",
    "# 确保预测特征窗口在历史数据范围内\n",
    "if (\n",
    "    prediction_feature_start_date.date() < historical_start_date.date()\n",
    "    or prediction_feature_end_date.date() > historical_end_date.date()\n",
    "):\n",
    "    print(\n",
    "        f\"错误：预测特征窗口 ({prediction_feature_start_date.date()} - {prediction_feature_end_date.date()}) 超出历史数据范围 ({historical_start_date.date()} - {historical_end_date.date()}).\"\n",
    "    )\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 提取预测日期的特征数据（前 lookback_days 的汇总）\n",
    "prediction_feature_window_data = daily_interactions[\n",
    "    (daily_interactions[\"Date\"] >= prediction_feature_start_date.date())\n",
    "    & (daily_interactions[\"Date\"] <= prediction_feature_end_date.date())\n",
    "]\n",
    "\n",
    "X_pred = []\n",
    "predict_blogger_ids = []\n",
    "\n",
    "# 确保为所有在历史数据中出现过的博主生成预测特征\n",
    "for blogger_id in all_blogger_ids:\n",
    "    blogger_features = prediction_feature_window_data[\n",
    "        prediction_feature_window_data[\"BloggerID\"] == blogger_id\n",
    "    ]\n",
    "\n",
    "    if blogger_features.empty:\n",
    "        features_row = [0, 0, 0, 0]  # 如果前lookback_days没有数据，特征为0\n",
    "    else:\n",
    "        # 汇总前 lookback_days 的数据\n",
    "        sum_features = (\n",
    "            blogger_features[\n",
    "                [\"watch_count\", \"like_count\", \"comment_count\", \"follow_count\"]\n",
    "            ]\n",
    "            .sum()\n",
    "            .tolist()\n",
    "        )\n",
    "        features_row = sum_features\n",
    "\n",
    "    X_pred.append(features_row)\n",
    "    predict_blogger_ids.append(blogger_id)\n",
    "\n",
    "X_pred = np.array(X_pred)\n",
    "\n",
    "print(f\"预测数据集构建完成，共 {len(X_pred)} 个样本.\")\n",
    "# print(\"X_pred sample:\", X_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在使用最终模型进行预测...\n",
      "预测完成.\n",
      "正在处理预测结果并生成排名...\n",
      "\n",
      "预测完成，2024.7.21 当日新增关注数最多的5位博主：\n",
      "表1: 2024.7.21 当日新增关注数最多的5位博主\n",
      "----------------------------------------\n",
      "| BloggerID   |   PredictedFollows_20240721 |\n",
      "|-------------|-----------------------------|\n",
      "| B21         |                         506 |\n",
      "| B5          |                         499 |\n",
      "| B15         |                         380 |\n",
      "| B60         |                         373 |\n",
      "| B13         |                         296 |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 8. 进行预测 ---\n",
    "print(\"正在使用最终模型进行预测...\")\n",
    "predictions = final_model.predict(X_pred)\n",
    "print(\"预测完成.\")\n",
    "\n",
    "# --- 9. 后处理与结果输出 ---\n",
    "print(\"正在处理预测结果并生成排名...\")\n",
    "\n",
    "# 确保预测结果非负并四舍五入取整\n",
    "predicted_follows = np.round(predictions).astype(int)\n",
    "predicted_follows[predicted_follows < 0] = 0\n",
    "\n",
    "# 构建结果DataFrame\n",
    "results_df = pd.DataFrame(\n",
    "    {\"BloggerID\": predict_blogger_ids, \"PredictedFollows_20240721\": predicted_follows}\n",
    ")\n",
    "\n",
    "# 按预测关注数降序排序\n",
    "results_df = results_df.sort_values(by=\"PredictedFollows_20240721\", ascending=False)\n",
    "\n",
    "# 选取前5位博主\n",
    "top_5_bloggers = results_df.head(5)\n",
    "\n",
    "print(\"\\n预测完成，2024.7.21 当日新增关注数最多的5位博主：\")\n",
    "# 按照表1格式输出\n",
    "print(\"表1: 2024.7.21 当日新增关注数最多的5位博主\")\n",
    "print(\"-\" * 40)\n",
    "# 使用 to_markdown 或 to_string 打印为表格格式\n",
    "try:\n",
    "    # 如果安装了 tabulate 库\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(tabulate(top_5_bloggers, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "except ImportError:\n",
    "    # 否则使用 to_string\n",
    "    print(\n",
    "        top_5_bloggers.rename(\n",
    "            columns={\"PredictedFollows_20240721\": \"新增关注数\"}\n",
    "        ).to_string(index=False)\n",
    "    )\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 可选：保存完整预测结果\n",
    "# results_df.to_csv('predicted_follows_20240721_all_bloggers.csv', index=False)\n",
    "# print(\"\\n所有博主的预测结果已保存至 'predicted_follows_20240721_all_bloggers.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
